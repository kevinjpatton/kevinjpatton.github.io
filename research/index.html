---
layout: research
title: Kevin Patton | Research
---
<p>I am deeply interested in the exploration of fundamental philosophical questions, particularly those concerning knowledge, language, logic, science, the mind, reality, and religion. My current research focuses on the intriguing intersection of epistemology, axiology, and the philosophical implications of artificial intelligence (AI), with a particular interest in the epistemological and ethical challenges posed by this rapidly developing technology. My teaching experience spans a diverse range of courses, including value theory, ethics / metaethics, formal logic, medical ethics, and aesthetics (with a special emphasis on the philosophical dimensions of video games). I occasionally venture into the enigmatic realm of metaphysics, though, much like Alice's adventures in Wonderland, I quickly search for a way out. Additionally, I have created some teaching materials which are available below and are free to use (there are more teaching materials on the <a href="/pedagogy/"><b>Pedagogy</b></a> page as well). To view previous syllabi for my classes, please click the <a href="/teaching"><b>Teaching</b></a> tab. Any published work of mine will also be hosted below.</p>
<div id="philpeople-component-follow_btn"></div>
<script type="text/javascript" src="https://philpeople.org/components/follow_btn?props%5B%3Aprofile_id_prop%5D=1087885&amp;props%5Bcontext%5D=external"></script>
<hr>
<h2>Publications</h2>
<ul class="standard-list">
  <li><p><b>We Need a Belmont Report for AI</b> in <i>AI & Society</i> (2025) <a href="https://link.springer.com/article/10.1007/s00146-025-02461-0" target="_blank">(OpenAccess)</a><br>This paper argues that the United States needs a legally enforceable ethical framework for artificial intelligence, modeled on the Belmont Report that transformed American biomedical research ethics. While many tech companies have adopted aspirational guidelines, these lack the enforcement mechanisms needed to ensure genuine accountability. A principles-based approach, I argue, offers a theory-neutral and morally flexible foundation for regulation. The paper ultimately calls for a National AI Act paired with a unifying ethical charter to proactively address AIâ€™s risks.</p></li>
</ul>
<h2>In-progress work intended for classroom use</h2>
<ul class="standard-list">
  <li>How to Philosophize - An Introduction to the Discipline for Undergraduates <a href="/research/Draft - How to Philosophize.pdf" target="_blank">(pdf)</a></li>
</ul>
<h2>Certifications</h2>
<ul class="standard-list">
  <li>Generative AI for Educators - from Google [<a href="https://skillshop.exceedlms.com/student/award/93LyjAzApz945Fhe2TqkuiFt" target="_blank">Link</a>]</li>
  <li>AI Essentials - Coursera and Google [<a href="/research/certs/googleaicert.pdf" target="_blank">Link</a>]</li>
  <li>AI Advantage - University of Nebraska at Omaha [<a href="https://badgr.com/public/assertions/936vTKqfRMK21Mkusq2AWg?identity__email=kevinpatton@unomaha.edu" target="_blank">Link</a>]</li>
  <li>AI Jumpstart - University of Nebraska at Omaha [<a href="https://badgr.com/public/assertions/ouVuFqFBScO2CiiZd2Tbig?identity__email=kevinpatton@unomaha.edu" target="_blank">Link</a>]</li>
</ul>
